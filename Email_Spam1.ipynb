{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gp2AY8ALpme6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/sample_data/emails.csv')\n",
        "\n",
        "# Separate features and labels\n",
        "X = data.iloc[:, 1:-1]  # Features (word counts)\n",
        "y = data[\"Prediction\"]       # Target labels (1 for spam, 0 for not spam)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize feature values\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# K-Nearest Neighbors\n",
        "knn = KNeighborsClassifier(n_neighbors=5)  # You can adjust the value of k\n",
        "knn.fit(X_train, y_train)\n",
        "knn_predictions = knn.predict(X_test)\n",
        "\n",
        "# SVM\n",
        "svm = SVC(kernel='linear')  # You can choose different kernels (linear, rbf, etc.)\n",
        "svm.fit(X_train, y_train)\n",
        "svm_predictions = svm.predict(X_test)\n",
        "\n",
        "# Evaluate K-NN\n",
        "confusion = confusion_matrix(y_test, knn_predictions)\n",
        "knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
        "print(\"K-NN Accuracy:\", knn_accuracy)\n",
        "print(\"Confusion Matrix:\\n\", confusion)\n",
        "# Evaluate SVM\n",
        "confusion = confusion_matrix(y_test, knn_predictions)\n",
        "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n",
        "print(\"Confusion Matrix:\\n\", confusion)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Nearest Neighbours is one of the most basic yet essential classification algorithms in Machine Learning. It belongs to the supervised learning domain and finds intense application in pattern recognition, data mining, and intrusion detection.\n",
        "\n",
        "It is widely disposable in real-life scenarios since it is non-parametric, meaning, it does not make any underlying assumptions about the distribution of data (as opposed to other algorithms such as GMM, which assume a Gaussian distribution of the given data). We are given some prior data (also called training data), which classifies coordinates into groups identified by an attribute.\n",
        "\n",
        "Applications of the KNN Algorithm\n",
        "Data Preprocessing – While dealing with any Machine Learning problem we first perform the EDA part in which if we find that the data contains missing values then there are multiple imputation methods are available as well. One of such method is KNN Imputer which is quite effective ad generally used for sophisticated imputation methodologies.\n",
        "Pattern Recognition – KNN algorithms work very well if you have trained a KNN algorithm using the MNIST dataset and then performed the evaluation process then you must have come across the fact that the accuracy is too high.\n",
        "Recommendation Engines – The main task which is performed by a KNN algorithm is to assign a new query point to a pre-existed group that has been created using a huge corpus of datasets. This is exactly what is required in the recommender systems to assign each user to a particular group and then provide them recommendations based on that group’s preferences.\n",
        "\n",
        "\n",
        "Support Vector Machine (SVM) is a powerful machine learning algorithm used for linear or nonlinear classification, regression, and even outlier detection tasks. SVMs can be used for a variety of tasks, such as text classification, image classification, spam detection, handwriting identification, gene expression analysis, face detection, and anomaly detection. SVMs are adaptable and efficient in a variety of applications because they can manage high-dimensional data and nonlinear relationships.\n",
        "\n",
        "SVM algorithms are very effective as we try to find the maximum separating hyperplane between the different classes available in the target feature.\n",
        "\n",
        "\n",
        "Linear SVM: Linear SVMs use a linear decision boundary to separate the data points of different classes. When the data can be precisely linearly separated, linear SVMs are very suitable. This means that a single straight line (in 2D) or a hyperplane (in higher dimensions) can entirely divide the data points into their respective classes. A hyperplane that maximizes the margin between the classes is the decision boundary.\n",
        "\n",
        "Non-Linear SVM: Non-Linear SVM can be used to classify data when it cannot be separated into two classes by a straight line (in the case of 2D). By using kernel functions, nonlinear SVMs can handle nonlinearly separable data. The original input data is transformed by these kernel functions into a higher-dimensional feature space, where the data points can be linearly separated. A linear SVM is used to locate a nonlinear decision boundary in this modified space\n",
        "\n",
        "Data Preprocessing:\n",
        "Data preprocessing is a process of preparing the raw data and making it suitable for amachine\n",
        "learning model. It is the rst and crucial step while creating a machine learning model.\n",
        "When creating a machine learning project, it is not always a case that we come across the clean and\n",
        "formatted data. And while doing any operation with data, it is mandatory to clean itand put in a formatted\n",
        "way. So for this, we use data preprocessing task."
      ],
      "metadata": {
        "id": "0gbPiINDqxkv"
      }
    }
  ]
}