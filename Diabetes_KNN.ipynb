{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSiRbXCpqpCp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
        "\n",
        "data = pd.read_csv('/content/sample_data/diabetes.csv')\n",
        "X = data.iloc[:, :-1]  # Features (all columns except the last one)\n",
        "y = data.iloc[:, -1]   # Target variable (the last column)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "k = 5  # You can choose the value of k (number of neighbors) as desired\n",
        "knn = KNeighborsClassifier(n_neighbors=k)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "error_rate = 1 - accuracy  # Error rate is 1 - Accuracy\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", confusion)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Error Rate:\", error_rate)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is K-Nearest Neighbors Algorithm?\n",
        "K-Nearest Neighbours is one of the most basic yet essential classification algorithms in Machine Learning. It belongs to the supervised learning domain and finds intense application in pattern recognition, data mining, and intrusion detection.\n",
        "\n",
        "It is widely disposable in real-life scenarios since it is non-parametric, meaning, it does not make any underlying assumptions about the distribution of data (as opposed to other algorithms such as GMM, which assume a Gaussian distribution of the given data). We are given some prior data (also called training data), which classifies coordinates into groups identified by an attribute.\n",
        "\n",
        "Applications of the KNN Algorithm\n",
        "Data Preprocessing – While dealing with any Machine Learning problem we first perform the EDA part in which if we find that the data contains missing values then there are multiple imputation methods are available as well. One of such method is KNN Imputer which is quite effective ad generally used for sophisticated imputation methodologies.\n",
        "Pattern Recognition – KNN algorithms work very well if you have trained a KNN algorithm using the MNIST dataset and then performed the evaluation process then you must have come across the fact that the accuracy is too high.\n",
        "\n",
        "The confusion matrix is a matrix used to determine the performance of the classification models for a given set of test data.\n",
        "True Negative: Model has given prediction No, and the real or actual value was also No.\n",
        "True Positive: The model has predicted yes, and the actual value was also true.\n",
        "False Negative: The model has predicted no, but the actual value was Yes, it is also called as Type-II error.\n",
        "False Positive: The model has predicted Yes, but the actual value was No. It is also called a Type-I error.\n",
        "Classification Accuracy: It is one of the important parameters to determine the accuracy of the classification problems. It defines how often the model predicts the correct output. It can be calculated as the ratio of the number of correct predictions made by the classifier to all number of predictions made by the classifiers\n",
        "Misclassification rate: It is also termed as Error rate, and it defines how often the model gives the wrong predictions. The value of error rate can be calculated as the number of incorrect predictions to all number of the predictions made by the classifier.\n",
        "Precision: It can be defined as the number of correct outputs provided by the model or out of all positive classes that have predicted correctly by the model, how many of them were actually true.\n",
        "Recall: It is defined as the out of total positive classes, how our model predicted correctly. The recall must be as high as possible\n"
      ],
      "metadata": {
        "id": "1TDps-9KnoLZ"
      }
    }
  ]
}